{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90d09601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Looking for images in 'chicken_briyani'\n",
      "INFO:tensorflow:Looking for images in 'chicken_curry'\n",
      "INFO:tensorflow:Looking for images in 'dosai'\n",
      "INFO:tensorflow:Looking for images in 'fried_rice'\n",
      "INFO:tensorflow:Looking for images in 'idly'\n",
      "INFO:tensorflow:Looking for images in 'poori'\n",
      "INFO:tensorflow:Looking for images in 'rice'\n",
      "INFO:tensorflow:Looking for images in 'vada'\n",
      "OrderedDict([('chicken briyani', {'dir': 'chicken_briyani', 'training': [], 'testing': ['download (1).jpg', 'download (2).jpg', 'download (3).jpg', 'download (4).jpg', 'download (5).jpg', 'download (6).jpg', 'download.jpg', 'images (1).jpg', 'images (2).jpg', 'images (3).jpg', 'images (4).jpg', 'images (5).jpg', 'images (6).jpg', 'images.jpg', 'download (1).jpg', 'download (2).jpg', 'download (3).jpg', 'download (4).jpg', 'download (5).jpg', 'download (6).jpg', 'download.jpg', 'images (1).jpg', 'images (2).jpg', 'images (3).jpg', 'images (4).jpg', 'images (5).jpg', 'images (6).jpg', 'images.jpg'], 'validation': []}), ('chicken curry', {'dir': 'chicken_curry', 'training': [], 'testing': ['1014843.jpg', '101833.jpg', '1022681.jpg', '1027623.jpg', '1035626.jpg', '1040283.jpg', '1068592.jpg', '108559.jpg', '1125163.jpg', '1133357.jpg', '1134602.jpg', '1014843.jpg', '101833.jpg', '1022681.jpg', '1027623.jpg', '1035626.jpg', '1040283.jpg', '1068592.jpg', '108559.jpg', '1125163.jpg', '1133357.jpg', '1134602.jpg'], 'validation': ['1004867.jpg', '1131377.jpg', '1004867.jpg', '1131377.jpg']}), ('dosai', {'dir': 'dosai', 'training': [], 'testing': ['download (1).jpg', 'download (2).jpg', 'download (4).jpg', 'download (5).jpg', 'download.jpg', 'images (1).jpg', 'images (2).jpg', 'images (3).jpg', 'images (4).jpg', 'images (5).jpg', 'images (6).jpg', 'images (7).jpg', 'images.jpg', 'download (1).jpg', 'download (2).jpg', 'download (4).jpg', 'download (5).jpg', 'download.jpg', 'images (1).jpg', 'images (2).jpg', 'images (3).jpg', 'images (4).jpg', 'images (5).jpg', 'images (6).jpg', 'images (7).jpg', 'images.jpg'], 'validation': []}), ('fried rice', {'dir': 'fried_rice', 'training': [], 'testing': ['1004221.jpg', '1008935.jpg', '1015700.jpg', '1019981.jpg', '1021229.jpg', '1022515.jpg', '1023430.jpg', '1028159.jpg', '1028939.jpg', '1042399.jpg', '1043233.jpg', '1043851.jpg', '1055787.jpg', '1059042.jpg', '1062698.jpg', '1076217.jpg', '1078011.jpg', '1085986.jpg', '1086742.jpg', '1095941.jpg', '1004221.jpg', '1008935.jpg', '1015700.jpg', '1019981.jpg', '1021229.jpg', '1022515.jpg', '1023430.jpg', '1028159.jpg', '1028939.jpg', '1042399.jpg', '1043233.jpg', '1043851.jpg', '1055787.jpg', '1059042.jpg', '1062698.jpg', '1076217.jpg', '1078011.jpg', '1085986.jpg', '1086742.jpg', '1095941.jpg'], 'validation': []}), ('idly', {'dir': 'idly', 'training': [], 'testing': ['download (1).jpg', 'download (2).jpg', 'download (3).jpg', 'download (4).jpg', 'download.jpg', 'images (1).jpg', 'images (2).jpg', 'images (3).jpg', 'images (4).jpg', 'images (5).jpg', 'images.jpg', 'download (1).jpg', 'download (2).jpg', 'download (3).jpg', 'download (4).jpg', 'download.jpg', 'images (1).jpg', 'images (2).jpg', 'images (3).jpg', 'images (4).jpg', 'images (5).jpg', 'images.jpg'], 'validation': ['images (6).jpg', 'images (6).jpg']}), ('poori', {'dir': 'poori', 'training': [], 'testing': ['download.jpg', 'images (1).jpg', 'images (3).jpg', 'images (4).jpg', 'images (5).jpg', 'images (6).jpg', 'images (7).jpg', 'images.jpg', 'download.jpg', 'images (1).jpg', 'images (3).jpg', 'images (4).jpg', 'images (5).jpg', 'images (6).jpg', 'images (7).jpg', 'images.jpg'], 'validation': ['download (1).jpg', 'download (2).jpg', 'download (4).jpg', 'images (2).jpg', 'download (1).jpg', 'download (2).jpg', 'download (4).jpg', 'images (2).jpg']}), ('rice', {'dir': 'rice', 'training': [], 'testing': ['download (1).jpg', 'download (2).jpg', 'download (3).jpg', 'download (5).jpg', 'download.jpg', 'images (1).jpg', 'images (3).jpg', 'images (4).jpg', 'images.jpg', 'download (1).jpg', 'download (2).jpg', 'download (3).jpg', 'download (5).jpg', 'download.jpg', 'images (1).jpg', 'images (3).jpg', 'images (4).jpg', 'images.jpg'], 'validation': ['images (2).jpg', 'images (2).jpg']}), ('vada', {'dir': 'vada', 'training': [], 'testing': ['download (3).jpg', 'download (6).jpg', 'images (11).jpg', 'images (12).jpg', 'images (13).jpg', 'images (14).jpg', 'images (15).jpg', 'images (16).jpg', 'images (9).jpg', 'download (3).jpg', 'download (6).jpg', 'images (11).jpg', 'images (12).jpg', 'images (13).jpg', 'images (14).jpg', 'images (15).jpg', 'images (16).jpg', 'images (9).jpg'], 'validation': ['images (10).jpg', 'images (8).jpg', 'images (10).jpg', 'images (8).jpg']})])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "# These are all parameters that are tied to the particular model architecture\n",
    "# we're using for Inception v3. These include things like tensor names and their\n",
    "# sizes. If you want to adapt this script to work with another model, you will\n",
    "# need to update these to reflect the values in the network you're using.\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
    "\n",
    "\n",
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "  \"\"\"Builds a list of training images from the file system.\n",
    "\n",
    "  Analyzes the sub folders in the image directory, splits them into stable\n",
    "  training, testing, and validation sets, and returns a data structure\n",
    "  describing the lists of images for each label and their paths.\n",
    "\n",
    "  Args:\n",
    "    image_dir: String path to a folder containing subfolders of images.\n",
    "    testing_percentage: Integer percentage of the images to reserve for tests.\n",
    "    validation_percentage: Integer percentage of images reserved for validation.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing an entry for each label subfolder, with images split\n",
    "    into training, testing, and validation sets within each label.\n",
    "  \"\"\"\n",
    "  if not gfile.Exists(image_dir):\n",
    "    tf.logging.error(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "    return None\n",
    "  result = collections.OrderedDict()\n",
    "  sub_dirs = [\n",
    "    os.path.join(image_dir,item)\n",
    "    for item in gfile.ListDirectory(image_dir)]\n",
    "  sub_dirs = sorted(item for item in sub_dirs\n",
    "                    if gfile.IsDirectory(item))\n",
    "  for sub_dir in sub_dirs:\n",
    "    extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "    file_list = []\n",
    "    dir_name = os.path.basename(sub_dir)\n",
    "    if dir_name == image_dir:\n",
    "      continue\n",
    "    tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")\n",
    "    for extension in extensions:\n",
    "      file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "      file_list.extend(gfile.Glob(file_glob))\n",
    "    if not file_list:\n",
    "      tf.logging.warning('No files found')\n",
    "      continue\n",
    "    if len(file_list) < 20:\n",
    "      tf.logging.warning(\n",
    "          'WARNING: Folder has less than 20 images, which may cause issues.')\n",
    "    elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "      tf.logging.warning(\n",
    "          'WARNING: Folder {} has more than {} images. Some images will '\n",
    "          'never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "    label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "    training_images = []\n",
    "    testing_images = []\n",
    "    validation_images = []\n",
    "    for file_name in file_list:\n",
    "      base_name = os.path.basename(file_name)\n",
    "      # We want to ignore anything after '_nohash_' in the file name when\n",
    "      # deciding which set to put an image in, the data set creator has a way of\n",
    "      # grouping photos that are close variations of each other. For example\n",
    "      # this is used in the plant disease data set to group multiple pictures of\n",
    "      # the same leaf.\n",
    "      hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "      # This looks a bit magical, but we need to decide whether this file should\n",
    "      # go into the training, testing, or validation sets, and we want to keep\n",
    "      # existing files in the same set even if more files are subsequently\n",
    "      # added.\n",
    "      # To do that, we need a stable way of deciding based on just the file name\n",
    "      # itself, so we do a hash of that and then use that to generate a\n",
    "      # probability value that we use to assign it.\n",
    "      hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "      percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                          (MAX_NUM_IMAGES_PER_CLASS + 1)) *\n",
    "                         (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "      if percentage_hash < validation_percentage:\n",
    "        validation_images.append(base_name)\n",
    "      elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        testing_images.append(base_name)\n",
    "      else:\n",
    "        training_images.append(base_name)\n",
    "    result[label_name] = {\n",
    "        'dir': dir_name,\n",
    "        'training': training_images,\n",
    "        'testing': testing_images,\n",
    "        'validation': validation_images,\n",
    "    }\n",
    "\n",
    "\n",
    "  return result\n",
    "\n",
    "print(create_image_lists(r\"C:\\Users\\darsh\\Desktop\\project\\Food_Recognition_System-WebApp (extract.me)\\food_dataset\", 90, 10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdc73f0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_lists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m   full_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, sub_dir, base_name)\n\u001b[0;32m     31\u001b[0m   \u001b[38;5;28mprint\u001b[39m(full_path)\n\u001b[1;32m---> 32\u001b[0m get_image_path(\u001b[43mimage_lists\u001b[49m, label_name, index, image_dir, category)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_lists' is not defined"
     ]
    }
   ],
   "source": [
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "  \"\"\"\"Returns a path to an image for a label at the given index.\n",
    "\n",
    "  Args:\n",
    "    image_lists: Dictionary of training images for each label.\n",
    "    label_name: Label string we want to get an image for.\n",
    "    index: Int offset of the image we want. This will be moduloed by the\n",
    "    available number of images for the label, so it can be arbitrarily large.\n",
    "    image_dir: Root folder string of the subfolders containing the training\n",
    "    images.\n",
    "    category: Name string of set to pull images from - training, testing, or\n",
    "    validation.\n",
    "\n",
    "  Returns:\n",
    "    File system path string to an image that meets the requested parameters.\n",
    "\n",
    "  \"\"\"\n",
    "  if label_name not in image_lists:\n",
    "    tf.logging.fatal('Label does not exist %s.', label_name)\n",
    "  label_lists = image_lists[label_name]\n",
    "  if category not in label_lists:\n",
    "    tf.logging.fatal('Category does not exist %s.', category)\n",
    "  category_list = label_lists[category]\n",
    "  if not category_list:\n",
    "    tf.logging.fatal('Label %s has no images in the category %s.',\n",
    "                     label_name, category)\n",
    "  mod_index = index % len(category_list)\n",
    "  base_name = category_list[mod_index]\n",
    "  sub_dir = label_lists['dir']\n",
    "  full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "  print(full_path)\n",
    "get_image_path(, label_name, index, image_dir, category)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892da8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
